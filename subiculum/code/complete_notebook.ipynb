{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import /Users/floseifert/Desktop/Subiculum/Stuff/subiculum/code/libraries/Neural_Lib_Flo as nlf \n",
    "import /Users/floseifert/Desktop/Subiculum/Stuff/subiculum/code/libraries/Training_Library as tl\n",
    "import /Users/floseifert/Desktop/Subiculum/Stuff/subiculum/code/libraries/wandb_library as wl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set the root directory\n",
    "root_dir_sensorium = '/project/data/static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6/data'\n",
    "images_path = '/project/subiculum/data/images_uint8.npy'\n",
    "v1_responses_path = '/project/subiculum/data/V1_Data.mat'\n",
    "sub_responses_path= '/project/subiculum/data/Post_Sub_Data.mat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have already run a sweep using wandb, so this won't be done again here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(\"seifertflo/V1 Training 17-06-2024/2mr3hewa\")\n",
    "config=run.config\n",
    "v1_model=nlb.configure_model(config, 13, device)\n",
    "v1_train_loader, v1_val_loader, v1_test_loader = nlb.dataloader_from_mat(images_path, v1_responses_path, 75, 125, 64)\n",
    "nlb.train_and_eval(model, config.get(\"epochs\"), v1_train_loader, v1_test_loader, v1_val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the same configuration to get a rough idea of what training with the Sub Data would give:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_loader, sub_val_loader, sub_test_loader =nlb.dataloader_from_mat(images_path, sub_responses_path, 75, 125, 64)\n",
    "sub_model=nlb.configure_model(config, 37, device)\n",
    "nlb.train_and_eval(sub_model, config.get(\"epochs\"),sub_train_loader, sub_val_loader, sub_test_loader, device), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one gets a correlation of ~30% for the Sensorium data, it would be helpful to understand why this is not reached for the v1 data here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Load Images to np.array\n",
    "images = np.load(images_path)\n",
    "\n",
    "# Load responses and preprocess them\n",
    "v1_responses, _, _ = load_mat_file(v1_responses_path)\n",
    "v1_responses = np.transpose(v1_responses, (1, 2, 0))\n",
    "\n",
    "# Look at mean data for neurons\n",
    "v1_responses_mean = np.mean(v1_responses, axis=0, keepdims=True)\n",
    "\n",
    "# Define the number of plots\n",
    "num_plots = 13\n",
    "neuron_indices = range(num_plots)\n",
    "\n",
    "# Create a 3x5 grid of subplots\n",
    "fig, axs = plt.subplots(3, 5, figsize=(15, 9))\n",
    "axs = axs.flatten()  # Flatten the 2D array to 1D for easier iteration\n",
    "\n",
    "# Create a custom legend patch\n",
    "legend_patch = mpatches.Patch(color='gray', alpha=0.5, label='Image shown')\n",
    "\n",
    "# Plot each neuron data\n",
    "x = np.arange(0, 2000, 10)\n",
    "for i, neuron_index in enumerate(neuron_indices):\n",
    "    if i < len(neuron_indices):  # Ensure we don't go out of bounds\n",
    "        neuron_mean = v1_responses_mean[:, :, neuron_index]\n",
    "        axs[i].plot(x, neuron_mean[0, :])\n",
    "        axs[i].axvspan(750, 1250, color='gray', alpha=0.5)  # Add transparent gray tile\n",
    "        axs[i].set_title(f'Neuron {neuron_index + 1}')\n",
    "        axs[i].set_xlabel('Time (ms)')\n",
    "        axs[i].set_ylabel('Response')\n",
    "        # Add the legend to the first plot only to avoid repetition\n",
    "        if i == 0:\n",
    "            axs[i].legend(handles=[legend_patch])\n",
    "\n",
    "# Remove empty subplots (if any)\n",
    "for j in range(len(neuron_indices), len(axs)):\n",
    "    fig.delaxes(axs[j])\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the structure of the responses.\n",
    "Now Ill compute oracle of the sensorium Data to compare the best neurons to the neurons here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensorium_train_loader, sensorium_val_loader, sensorium_test_loader = nlb.dataloader_from_npy_pretraining(root_dir_sensorium, device)\n",
    "sensorium_model = \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
